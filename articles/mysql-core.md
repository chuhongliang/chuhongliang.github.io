# MySQL 知识点
- [索引](#索引)
- [调优](#调优)
- [存储引擎](#存储引擎)
- [事务](#事务)
- [锁](#锁)
- [MVCC](#MVCC)
- [日志系统](#日志系统)
- 主从复制
- 读写分离
- 分库分表 
- [参考资料](http://mysql.taobao.org/monthly/2017/12/01/)

# MySQL Server
- 连接器: 管理连接，验证权限
- 分析器: 词法分析，语法分析
- 优化器: （用户无法控制）
  - CBO: 基于成本的优化，应该比较广泛
  - RBO: 基于规则的优化，
- 执行器: 用来跟存储引擎直接交互。

## 索引
索引是帮助MySQL高效获取数据的排好序的数据结构

> 1. 局部性原理：数据和程序都有聚集成群的倾向，分为空间局部性和时间局部性。
> 2. 磁盘预读：内存跟磁盘在进行交互的时候要保证每次读取数据需要一个逻辑单位，而这个逻辑单位叫做页。或者叫datapage, 一般都是4K或者8K， 在进行读取的时候一般都是4K的整数倍。
innodb每次读取16KB。 [参考资料](https://blog.csdn.net/weixin_36043375/article/details/113349291)

### 索引的数据结构：
- hash: memory 使用hash索引，innodb支持自适应hash索引。单行查询快，不支持范围查询
- 树: 
  - 二叉树：存在单边增长的问题
  - 红黑树(平衡树)：
  - B 树(B-树)：
    - 叶子节点具有相同的深度
    - 叶子节点的指针为空
    - 节点中的数据索引从左到右递增排列
  - B+ 树: 
    - 多叉树
    - 节点有序
    - 每一个节点可以存储多条记录
    - 非叶子节点不存储data，只存储索引，可以放更多的索引
    - 叶子节点包含所有的索引字段
    - 叶子节点用指针连指顺序访问，提高区间访问的性能


### mysql的索引一般有几层？
一般情况下，3到4层就足以支撑千万级别的表的查询。

### 创建索引的字段是长了好还是短了好？
短了好，原因是在层数不变的情况下可以存储更多的数据量。

### 创建表的时候是用代理主键还是用自然主键？
- 代理主键：跟业务无关字段（id）
- 自然主键：跟业务有关的字段（phonenumber）
能使用代理主键尽可能的使用代理主键。

### 主键设置好之后，要不要自增？
在满足业务的情况下尽可能自增，不自增会增加索引的维护成本。

### 在分布式应用场中，自增id还适用吗？
不适用，雪花算法snowflake, 自定义id生成器。

### 聚簇索引和非聚簇索引
- 聚簇索引: 数据跟索引聚集存储的　innodb的主键索引
  - innodb的主键索引就是聚簇索引，必须要包含一个主键列的：key (直接存放数据)
  - 如果在创建表的时候制定了主键，那么key就是主键，如果没有主键，那么key就是唯一键。如果唯一键也没有，那么key就是6字节的rowID。
- 非聚簇索索引：数据跟索引不是聚集存储的
  - myisam 的所有索引
  - innodb 的二级索引(辅助索引，普通索引) (辅助索引，普通索引的叶子节点存放主键)(一致性和节省存储空间)

### 回表查询
InnoDB普通索引的叶子节点存储主键值，普通索引因为无法直接定位行记录，其查询过程在通常情况下是需要扫描两遍索引树。

### 最左匹配原则
在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

### 索引下推
简称ICP，在Mysql5.6的版本上推出，用于优化查询。

其实就是对索引失效的进一步修复，属于最左前缀索引原则的一个意外情况。

索引下推触发的条件
- 查询条件是符合索引
- 失效条件的字段在索引覆盖的范围内
- 失效条件是可以通过数据进行比较的简单对比


### 索引覆盖
索引覆盖是一种避免回表查询的优化策略。具体的做法就是将要查询的数据作为索引列建立普通索引（可以是单列索引，也可以一个索引语句定义所有要查询的列，即联合索引），这样的话就可以直接返回索引中的的数据，不需要再通过聚集索引去定位行记录，避免了回表的情况发生。

#### 注意事项
如果一个索引覆盖（包含）了所有需要查询的字段的值，这个索引就是覆盖索引。因为索引中已经包含了要查询的字段的值，因此查询的时候直接返回索引中的字段值就可以了，不需要再到表中查询，避免了对主键索引的二次查询，也就提高了查询的效率。

要注意的是，不是所有类型的索引都可以成为覆盖索引的。因为覆盖索引必须要存储索引的列值，而哈希索引、空间索引和全文索引等都不存储索引列值，索引MySQL只能使用B-Tree索引做覆盖索引。

另外，当发起一个被索引覆盖的查询（索引覆盖查询）时，在explain（执行计划）的Extra列可以看到【Using Index】的信息。

#### 覆盖索引的优点

- 1.索引条目通常远小于数据行的大小，因为覆盖索引只需要读取索引，极大地减少了数据的访问量。

- 2.索引是按照列值顺序存储的，对于IO密集的范围查找会比随机从磁盘读取每一行数据的IO小很多。

- 3.一些存储引擎比如MyISAM在内存中只缓存索引，数据则依赖操作系统来缓存，因此要访问数据的话需要一次系统调用，使用覆盖索引则避免了这一点。

- 4.由于InnoDB的聚簇索引，覆盖索引对InnoDB引擎下的数据库表特别有用。因为InnoDB的二级索引在叶子节点中保存了行的主键值，如果二级索引能够覆盖查询，就避免了对主键索引的二次查询。

### 索引失效
- 1、对列使用函数，该列的索引将不起作用。
  - 如：substring(字段名,1,2)='xxx'；

- 2、对列进行运算(+，-，*，/，! 等)，该列的索引将不起作用。
  - 如：
  ```sql
  select * from test where id-1=9;//错误的写法；

  select * from test where id=10; //正确的写法 ；
  ```

- 3、某些情况下的LIKE操作，该列的索引将不起作用。

  - 如：字段名 LIKE CONCAT('%', '2014 - 08 - 13', '%') ；

- 4、某些情况使用反向操作，该列的索引将不起作用。

  - 如：字段名 <> 2；

- 5、在WHERE中使用OR时，有一个列没有索引，那么其它列的索引将不起作用。

- 6、隐式转换导致索引失效.这一点应当引起重视.也是开发中经常会犯的错误。

  - 由于表的字段t_number定义为varchar2(20),但在查询时把该字段作为number类型以where条件传给Oracle,这样会导致索引失效。

  - 如: 
  ```sql
  select * from test where t_number=13333333333;  //错误的写法；

  select * from test where t_number='13333333333'; //正确的写法；
  ```
- 7、使用not in ,not exist等语句时。

- 8、当变量采用的是times变量，而表的字段采用的是date变量时.或相反情况。

- 9、当B-tree索引 is null不会失效,使用is not null时,会失效,位图索引 is null,is not null 都会失效。

- 10、联合索引 is not null 只要在建立的索引列（不分先后）都会失效。

  - in null时 必须要和建立索引第一列一起使用,当建立索引第一位置条件是is null 时,其他建立索引的列可以是is null（但必须在所有列 都满足is null的时候）,或者 = 一个值；

  - 当建立索引的第一位置是 = 一个值时,其他索引列可以是任何情况（包括is null  = 一个值）,以上两种情况索引都会失效,其他情况不会失效。

## 调优
参考资料：https://www.cnblogs.com/igoodful/p/9360863.html

### 基础规范
1. 不在数据库做运算：cpu计算务必移至业务层
2. 控制单表数据量：单表记录控制在1000w
3. 控制列数量：字段数控制在20以内
4. 平衡范式与冗余：为提高效率牺牲范式设计，冗余数据
5. 拒绝3B：拒绝大sql，大事物，大批量
6. 表存储引擎必须使用InnoDB（通用，无乱码风险，汉字3字节，英文1字节）
7. 表字符集默认使用utf8，必要时候使用utf8mb4（utf8mb4是utf8的超集，有存储4字节例如表情符号时，使用它）
8. 禁止使用存储过程，视图，触发器，Event
   - 对数据库性能影响较大，互联网业务，能让站点层和服务层干的事情，不要交到数据库层
   - 调试，排错，迁移都比较困难，扩展性较差
9. 禁止在数据库中存储大文件，例如照片，可以将大文件存储在对象存储系统，数据库中存储路径
10. 禁止在线上环境做数据库压力测试
11. 测试，开发，线上数据库环境必须隔离

### 命名规范
1. 库名，表名，列名必须用小写，采用下划线分隔
   - 解读：abc，Abc，ABC都是给自己埋坑
2. 库名，表名，列名必须见名知义，长度不要超过32字符
   - 解读：tmp，wushan谁TM知道这些库是干嘛的....
3. 库备份必须以bak为前缀，以日期为后缀
4. 从库必须以-s为后缀
5. 备库必须以-ss为后缀

### 表设计规范
1. 单实例表个数必须控制在2000个以内
2. 单表分表个数必须控制在1024个以内
3. 表必须有主键，推荐使用UNSIGNED整数为主键
  - 潜在坑：删除无主键的表，如果是row模式的主从架构，从库会挂住
4. 禁止使用外键，如果要保证完整性，应由应用程式实现
  - 解读：外键使得表之间相互耦合，影响update/delete等SQL性能，有可能造成死锁，高并发情况下容易成为数据库瓶颈
5. 建议将大字段，访问频度低的字段拆分到单独的表中存储，分离冷热数据


### 列设计规范
1. 根据业务区分使用tinyint/smallint/mediumint/int/bigint
    ```sql
    tinyint(1Byte)     -128 - 127
    smallint(2Byte)    -32768 - 32767
    mediumint(3Byte)   -8388608 - 8388607
    int(4Byte)         -2147483648 - 2147483647
    bigint(8Byte)      -9223372036854775808 - 9223372036854775807
    ```

2. 根据业务区分使用char/varchar
   - 字段长度固定，或者长度近似的业务场景，适合使用char，能够减少碎片，查询性能高
   - 字段长度相差较大，或者更新较少的业务场景，适合使用varchar，能够减少空间

3. 根据业务区分使用datetime/timestamp
   - 解读：前者占用5个字节，后者占用4个字节，存储年使用YEAR，存储日期使用DATE，存储时间使用datetime

4. 必须把字段定义为NOT NULL并设默认值
   - NULL的列使用索引，索引统计，值都更加复杂，MySQL更难优化
   - NULL需要更多的存储空间
   - NULL只能采用IS NULL或者IS NOT NULL，而在=/!=/in/not in时有大坑

5. 使用varchar(20)存储手机号，不要使用整数
   - 牵扯到国家代号，可能出现+/-/()等字符，例如+86
   - 手机号不会用来做数学运算
   - varchar可以模糊查询，例如like ‘138%’

6. 使用INT UNSIGNED存储IPv4，不要用char(15)

7. 使用TINYINT来代替ENUM
    - 解读：ENUM增加新值要进行DDL操作

8. 少用text/blob
     - varchar的性能会比text高很多
     - 实在避免不了blob，请拆表

9. 不在数据库里存图片：是否需要解释？


### 索引规范
1. 唯一索引使用uniq_[字段名]来命名
2. 非唯一索引使用idx_[字段名]来命名
3. 单张表索引数量建议控制在5个以内
    - 互联网高并发业务，太多索引会影响写性能
    - 生成执行计划时，如果索引太多，会降低性能，并可能导致MySQL选择不到最优索引
    - 异常复杂的查询需求，可以选择ES等更为适合的方式存储

4. 组合索引字段数不建议超过5个
    - 解读：如果5个字段还不能极大缩小row范围，八成是设计有问题

5. 不建议在频繁更新的字段上建立索引
6. 非必要不要进行JOIN查询，如果要进行JOIN查询，被JOIN的字段必须类型相同，并建立索引
    - 解读：踩过因为JOIN字段类型不一致，而导致全表扫描的坑么？
7. 理解组合索引最左前缀原则，避免重复建设索引，如果建立了(a,b,c)，相当于建立了(a), (a,b),(a,b,c)

8. 不在索引做列运算

9. 不用外键
    - 请由程序保证约束

10. innodb主键推荐使用自增列
    - 主键建立聚簇索引
    - 主键不应该被修改
    - 字符串不应该做主键
    - 如果不指定主键，innodb会使用唯一且非空值索引代替

### SQL规范
1. 禁止使用select *，只获取必要字段
    - select *会增加cpu/io/内存/带宽的消耗
2. 隐式类型转换会使索引失效，导致全表扫描
3. 禁止在where条件列使用函数或者表达式
    - 导致不能命中索引，全表扫描
4. 禁止负向查询以及%开头的模糊查询
   - 导致不能命中索引，全表扫描
5. 禁止大表JOIN和子查询
6. 同一个字段上的OR必须改写成IN，IN的值必须少于50个
7. 应用程序必须捕获SQL异常
   - 方便定位线上问题
8. 避免使用trig/func
   - 触发器、函数不用
   - 客户端程序取而代之
9. 简单的事务
   - 事务时间尽可能短
10. sql语句尽可能简单
   - 一条sql只能在一个cpu运算
   - 大语句拆小语句，减少锁时间
   - 一条大sql可以堵死整个库

11. OR改写为UNION
   - mysql的索引合并很弱智
   ```sql
    　 select id from t where phone = ’159′ or name = ‘john’;
        =>
       select id from t where phone=’159′ union select id from t where name=’jonh’;
   ```

12. 慎用count(*)

13. limit高效分页 limit越大，效率越低 
    ```sql
      select id from t limit 10000, 10; 
      => 
      select id from t where id > 10000 limit 10; 
    ```
14. 使用union all替代union 
    - union有去重开销 
15. 少用连接join

16. 使用group by 
    - 分组； 
    - 自动排序；

17. 请使用同类型比较 
18. 使用load data导数据 
    load data 比 insert 快约20倍； 

19. 打散批量更新 

20. 新能分析工具 
    - show profile; 
    - mysqlsla;
    - mysqldumpslow; 
    - explain; 
    - show slow log; 
    - show processlist; 
    - show query_response_time(percona);



## 存储引擎
定义：不同的数据文件在磁盘的不同组织形式。

分类：
- innodb
- myisam
- memory(Heap)


### innodb 和 myisam 的区别
- innodb 支持事务，myisam不支持
- innodb 支持外键，myisam不支持
- innodb 支持表锁和行锁，myisam只支持表锁
- innodb 在5.6版本之后支持全文索引， myisam 一直支持全文索引
- innodb 索引的叶子节点直接存放数据（聚簇索引），myisam 存放地址（非聚簇索引: 就是索引与行数据分开存储）。



## 事务
- 原子性：undo log 　保存的是跟执行操作相反的操作，用于回滚。保证原子性，参与部分的mvcc(多版本并发控制)操作。
- 一致性：
- 隔离性：用锁来保证 
  - 读未提交：会触发脏读，幻读，不可重复读。
  - 读已提交：会触发幻读，不可重复读。   读取的是最新的一致性的快照版本。
  - 可重复读：会触发幻读　(默认级别)　　 读取的是事务开启之前的版本。(读的快照)
  - 串行化(序列化)：
  - 隔离级别越低，效率越高，越不安全；隔离级别越高，效率越低，越安全。
- 持久性：redo log 　为了保证 crash safe; 如果发生异常情况，就算数据没有持久化成功，只要日志持久化成功了，依然可以进行恢复。

### 更新丢失（lost update）
当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题，最后的更新覆盖了由其他事务所做的更新。

### 脏读（dirty reads）(读取了前一事务 未提交 的数据)
一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。

### 不可重复读（non-repeatable reads）(读取了前一事务提交 的数据)
一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变或某些记录已经被删除了！这种现象就是“不可重复读”。

### 幻读（phantom reads）
一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象称为“幻读”。

### 事务隔离级别
并发事务处理带来的问题中，“更新丢失”，通常是可以避免的，需要应用程序对要更新的数据加必要的锁来解决。

“脏读”，“不可重复读”和“幻读”， 其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。

数据库实现事务隔离的方式，基本可以分为两种：
- 在读取数据前，对其加锁，阻止其他事务对数据进行修改
- 不加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照，这种方式叫做数据多版本并发控制。

数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。为了解决“隔离”与“并发”的矛盾，ISO/ANSI SQL92 定义了 4 个事务隔离级别，MySQL 实现了这四种级别，应用可以根据自己的业务逻辑要求，选择合适的隔离级别来平衡“隔离”与“并发”的矛盾。



## 锁
锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。锁是Mysql在服务器层和存储引擎层的的并发控制。

加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否是否已解除、释放锁等。

### 共享锁与排他锁
- 共享锁（读锁）：其他事务可以读，但不能写。
- 排他锁（写锁）：其他事务不能读取，也不能写。

### 粒度锁
MySQL 不同的存储引擎支持不同的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现：
- 表级锁: MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking）
- 页面锁: BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁
- 行级锁: InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。

默认情况下，表锁和行锁都是自动获得的， 不需要额外的命令。

但是在有的情况下， 用户需要明确地进行锁表或者进行事务的控制， 以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。

### 不同粒度锁的比较：
1. 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
    - 这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁。
    - 表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如Web 应用
2. 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
    - 最大程度的支持并发，同时也带来了最大的锁开销。
    - 在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的。
    - 行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统
3. 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。


### MyISAM 表锁
MyISAM表级锁模式：
- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；



### MyISAM 的锁调度
#### MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。

#### 默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。
这也正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。

同时，一些需要长时间运行的查询操作，也会使写线程“饿死” ，应用中应尽量避免出现长时间运行的查询操作
 - 在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解” ，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。

MyISAM设置改变读锁和写锁的优先级：
- 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。
- 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。
- 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。
- 给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。

### MyISAM加表锁方法：
MyISAM 在执行查询语句（SELECT）前，会自动给涉及的表加读锁，在执行更新操作
（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。

在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。

### MyISAM并发插入（concurrent inserts）
myisam 表的读和写是串行的，但这是就总体而言的。在一定条件下，myisam 表也支持查询和插入操作的并发进行。
myisam 存储引擎有一个系统变量 concurrent_insert , 专门用以控制其并发插入的行为，其值分别可以为0,1,2。

- 当 concurrent_insert 设置为 0 时，不允许并发插入。
- 当 concurrent_insert 设置为 1 时，如果 myisam 表中没有空洞（即表的中间没有被删除的行），myisam 允许在一个进程读表的同时，另一个进程从表尾插入记录。这也是 MySQL 的默认设置。
- 当 concurrent_insert 设置为 2 时，无论 myisam 表中有没有空洞，都允许在表尾并发插入记录。

查询表级锁争用情况：

可以通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况：
```sql
mysql> SHOW STATUS LIKE 'Table%';
+-----------------------+---------+
| Variable_name | Value |
+-----------------------+---------+
| Table_locks_immediate | 1151552 |
| Table_locks_waited | 15324 |
+-----------------------+---------+
```


### InnoDB 锁
InnoDB 实现了以下两种类型的行锁：
- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁：
- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

```sql
+-----------------------+---------+-----------------------+---------+------------+
| 　　    锁名称　　  | 共享锁(S) |  排他锁(X) |  意向共享锁(IS) |  意向排他锁(IX) |
+-----------------------+---------+-----------------------+---------+------------+
| 排他锁(X)          |    冲突   |     冲突   |       冲突     |      冲突     |
| 意向排他锁(IX)     |    冲突   |     兼容   |       冲突     |      兼容     |
| 共享锁(S)　        |    冲突   |     冲突   |       兼容     |      兼容     |
| 意向共享锁(IS)     |    冲突   |     兼容   |       兼容     |      兼容     |
+-----------------------+---------+-----------------------+---------+------------+
```
如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务； 反之， 如果两者不兼容，该事务就要等待锁释放

### InnoDB加锁方法：
- 意向锁是 InnoDB 自动加的， 不需用户干预。
- 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB会自动给涉及数据集加排他锁（X)；
- 对于普通 SELECT 语句，InnoDB 不会加任何锁；
- 事务可以通过以下语句显式给记录集加共享锁或排他锁：
    - 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。
    - 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁


#### 隐式锁定：
- InnoDB在事务执行过程中，使用两阶段锁协议：
- 随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；
- 锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在同一时刻被释放。

#### 显式锁定：
```sql
select ... lock in share mode // 共享锁 
select ... for update // 排他锁  
```

select for update：
- 作用: 在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。
- 使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。
- 性能：相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。

select lock in share mode ：
- 作用: in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。
- 使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。
- 性能：是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。


for update 和 lock in share mode 的区别：
- for update 上的是排他锁（X 锁），一旦一个事务获取了这个锁，其他的事务是没法在这些数据上执行 for update ；
- lock in share mode 是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。


#### InnoDB 行锁实现方式：
InnoDB 行锁是通过给索引项加锁来实现的，如果么有索引，innodb 将通过隐藏的聚簇索引来对记录加锁。innodb 行锁分为 3 种情形：
- record lock： 对索引项加锁
- gap lock： 对索引项之间的“间隙”、第一条记录前的“间隙”或最后一条记录的“间隙”加锁。
- next-key lock： 前两种的结合，对记录及其前面的间隙加锁。

InnoDB 这种行锁实现特点意味着：如果不通过索引条件检索数据，那么 innodb 将对表中的所有记录加锁，实际效果和表锁一样！

在实际应用中，要特别注意 innodb 行锁的这一特性，否则可能导致大量的锁冲突，从而影响并发性能。
- 在不通过索引条件查询的时候，InnoDB确实使用的是表锁，而不是行锁。
- 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。
- 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。
- 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。


### InnoDB的间隙锁（Next-Key锁）
当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。

#### InnoDB使用间隙锁的目的：
- 防止幻读，以满足相关隔离级别的要求；
- 满足恢复和复制的需要：

#### 恢复和复制的需要，对 innodb 锁机制的影响
MySQL 通过 binlog 记录执行成功的 insert、update 、delete 等更新数据的 sql 语句，并由此实现 MySQL 数据库的恢复和主从复制。MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点：
1. MySQL 的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中的 SQL 语句。
2. MySQL 的 Binlog 是按照事务提交的先后顺序记录的， 恢复也是按这个顺序进行的。

MySQL 5.6 支持 3 种 日志格式，即基于语句的日志格式 sbl，基于行的日志格式 rbl 和混合格式。它还支持 4 种复制模式：

- 基于 sql 语句的复制 sbr：这也是 MySQL 最早支持的复制模式。
- 基于 行数据的复制 rbr： 这是 MySQL5.1 以后喀什支持的复制模式，主要优点是支持对非安全 sql 的复制模式。
- 混合复制模式：对安全的 sql 语句采用基于 sql 语句的复制模式，对于非安全的 sql 语句采用局于行的复制模式。
- 使用全局事务id（gtids）的复制：主要是解决主从自动同步一致的问题。

对基于语句日志格式（sbl）的恢复和复制而言，由于 MySQL 的 binlog 是按照事务提交的先后顺序记录的，因此要正确恢复或复制数据，就必须满足：

在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。

这已经超过了“可重复读”隔离级别的要求，实际上是要求事务要串行化。这也是许多情况下，innodb 要用 next-key 锁的原因。


### 什么时候使用表锁
对于 innodb 表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们选择 innodb 表的理由，但在个别特殊任务中，也可以考虑使用表级锁：
1. 事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁
2. 事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定多个表，从而避免死锁，减少数据库因事务回滚带来的开销。

当然，应用中这两种事务不能太多，否则，就应该考虑使用 myisam 表了。
#### 在 innodb 下，使用表锁要注意以下两点：
1. 使用 lock tables 虽然可以给 innodb 加表级锁，但必须说明的是，表锁不是由 innodb 存储引擎管理的，而是由其上一层———— MySQL server 负责的，仅当 autocommit=0、innodb_table_locks=1(默认设置)时，innodb 层才知道 MySQL 加的表锁，MySQL server 也才能够感知 innodb 加的行锁，这种情况下，innodb 才能自动识别涉及到的锁。
2. 在用 lock_tables 对 innodb 表加锁时要注意，要将 autocommit 设为 0，否则 MySQL 不会给表加锁；事务结束前，不要用 unlock tables 释放表锁，因为 unlock tables 会隐含的提交事务；commit 或 rollback 并不能释放用 lock tables 加的表锁，必须用 unlock tables 释放表锁


### 死锁
MyISAM表锁是deadlock free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了在InnoDB中发生死锁是可能的。

发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数 innodb_lock_wait_timeout来解决。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。


#### 避免死锁的常用方法
1. 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。在下面的例子中，由于两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可以避免。
2. 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。
3. 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。
4. 前面讲过，在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT...FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可避免问题。
5. 当隔离级别为READ COMMITTED时，如果两个线程都先执行SELECT...FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第3个线程又来申请排他锁，也会出现死锁。

如果出现死锁，可以用SHOW INNODB STATUS命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

#### 一些优化锁性能的建议
- 尽量使用较低的隔离级别；
- 精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会
- 选择合理的事务大小，小事务发生锁冲突的几率也更小
- 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁
- 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会
- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- 除非必须，查询时不要显示加锁。 MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能；MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作
- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能

### 乐观锁、悲观锁
#### 乐观锁(Optimistic Lock)：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。
乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。

#### 悲观锁(Pessimistic Lock)：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。
悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。



## MVCC 机制
http://mysql.taobao.org/monthly/2017/12/01/
https://blog.csdn.net/SnailMann/article/details/94724197
>全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。





## 日志系统
### MySQL中有以下日志文件，分别是：
1. 重做日志（redo log）
2. 回滚日志（undo log）
3. 二进制日志（binlog）
4. 错误日志（errorlog）
5. 慢查询日志（slow query log）
6. 一般查询日志（general log）
7. 中继日志（relay log）。

#### 其中重做日志和回滚日志与事务操作息息相关，二进制日志也与事务操作有一定的关系，这三种日志，对理解MySQL中的事务操作有着重要的意义。

### 重做日志（redo log）
和大多数关系型数据库一样，InnoDB 记录了对数据文件的物理更改，并保证总是日志先行，也就是所谓的 WAL，即在持久化数据文件前，保证之前的 redo 日志已经写到磁盘。由于 redo log 是顺序整块写入，所以性能要更好。

重做日志两部分组成：一是内存中的重做日志缓冲(redo log buffer)，是易失的；二是重做日志文件(redo log file)，是持久的。redo log 记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。

#### 作用：
- 确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

#### 写入过程
在一条语句进行执行的时候，InnoDB 引擎会把新记录写到 redo log 日志中，然后更新内存，更新完成后就算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中。

更详细的步骤，需要了解两个关键词：checkpoint 和 LSN(Log Sequence Number)，前者检查点简单来说就是把脏页刷到磁盘的时间点，这个时间点之前的数据都已经保存到了持久存储。而 LSN 是 InnoDB 使用的一个版本标记的计数，它是一个单调递增的值。数据页和 redo log 都有各自的 LSN。每次把 redo log 中的内容写入到实际的数据页之后，就会把 LSN 也同步过去。如果发生了宕机，我们可以根据数据页中的 LSN 值和 redo log 中 LSN 的值判断需要恢复的 redo log 的位置和大小。redo log 同样也有自己的缓存，所以也涉及到刷盘策略，是通过innodb_flush_log_at_trx_commit这个参数控制的。

当对应事务的脏页写入到磁盘之后，redo log 的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

#### 存储结构
这一块应该就没必要深入了，redo log 的存储都是以块(block)为单位进行存储的，每个块的大小为 512 字节。同磁盘扇区大小一致，可以保证块的写入是原子操作。

另外 redo log 占用的空间是固定的，会循环写入。文件大小由innodb_log_file_size参数控制。


#### 内容：
- 物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。

#### 什么时候产生：
- 事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。

#### 什么时候释放：
- 当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

#### 对应的物理文件：
- 默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&ib_logfile2
- innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。
- innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2


#### 关于文件的大小和数量，由以下两个参数配置：
- innodb_log_file_size 重做日志文件的大小。
- innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1

#### 其他：
很重要一点，redo log是什么时候写盘的？前面说了是在事物开始之后逐步写盘的。

之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。

然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘
- Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。
- 每个事务提交时会将重做日志刷新到重做日志文件。
- 当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件
- 由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。
- 因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。

另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：
- 即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。
- 这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。


### 回滚日志（undo log）
undo log 有两个作用：提供回滚和多版本并发控制下的读(MVCC)，也即非锁定读

在数据修改的时候，不仅记录了redo，还记录了相对应的 undo，如果因为某些原因导致事务失败或回滚了，可以借助该 undo 进行回滚。

undo log 和 redo log 记录物理日志不一样，它是逻辑日志。可以认为当 delete 一条记录时，undo log 中会记录一条对应的 insert 记录，反之亦然，当 update 一条记录时，它记录一条对应相反的 update 记录。

有时候应用到行版本控制的时候，也是通过 undo log 来实现的：当读取的某一行被其他事务锁定时，它可以从 undo log 中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。

undo log 是采用段(segment)的方式来记录的，每个 undo 操作在记录的时候占用一个 undo log segment。

另外，undo log 也会产生 redo log，因为 undo log 也要实现持久性保护。

当事务提交的时候，InnoDB 不会立即删除 undo log，因为后续还可能会用到 undo log，如隔离级别为 repeatable read 时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即 undo log 不能删除。

当事务提交之后，undo log 并不能立马被删除，而是放入待清理的链表，由 purge 线程判断是否有其他事务在使用 undo 段中表的上一个事务之前的版本信息，决定是否可以清理 undo log 的日志空间。

在 MySQL 5.7 之前，undo log 存储在共享表空间中，因此有可能大大增加表空间的占用，5.7 之后可以通过配置选择存储在独立的表空间中。

#### 作用：
- 保证数据的原子性，保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

#### 内容：
- 逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

#### 什么时候产生：
- 事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性

#### 什么时候释放：
- 当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间

#### 对应的物理文件：
- MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。
- MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数
- 如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。

#### 关于MySQL5.7之后的独立undo 表空间配置参数如下：
- innodb_undo_directory = /data/undospace/ –undo独立表空间的存放目录 innodb_undo_logs = 128 –回滚段为128KB innodb_undo_tablespaces = 4 –指定有4个undo log文件
- 如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。

#### 其他：
- undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。
- 默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。
- 因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。
- 因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。

### undo log 和 redo log
undo log 和 redo log 其实都不是 MySQL 数据库层面的日志，而是 InnoDB 存储引擎的日志。二者的作用联系紧密，事务的隔离性由锁来实现，原子性、一致性、持久性通过数据库的 redo log 或 redo log 来完成。redo log 又称为重做日志，用来保证事务的持久性，undo log 用来保证事务的原子性和 MVCC。

### 二进制日志（binlog）
binlog 是 没有 MySQL sever 层维护的一种二进制日志，与 innodb 引擎中的 redo/undo log 是完全不同的日志。其主要是用来记录对 MySQL 数据更新或潜在发生更新的 SQL 语句，并以 “事务”的形式保存在磁盘中。
#### 作用：
- 复制：MySQL 主从复制在 Master 端开启 binlog，Master 把它的二进制日志传递给 slaves 并回放来达到 master-slave 数据一致的目的
- 数据恢复：通过 mysqlbinlog 工具恢复数据
- 增量备份

#### 主从复制
复制是 MySQL 最重要的功能之一，MySQL 集群的高可用、负载均衡和读写分离都是基于复制来实现。复制步骤如下：

1. Master 将数据改变记录到二进制日志(binary log)中。
2. Slave 上面的 IO 进程连接上 Master，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。
3. Master 接收到来自 Slave 的 IO 进程的请求后，负责复制的 IO 进程会根据请求信息读取日志指定位置之后的日志信息，返回给 Slave 的 IO 进程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息已经到 Master 端的 binlog 文件的名称以及 binlog 的位置。
4. Slave 的 IO 进程接收到信息后，将接收到的日志内容依次添加到 Slave 端的 relaylog 文件的最末端，并将读取到的 Master 端的 binlog 的文件名和位置记录到 masterinfo 文件中，以便在下一次读取的时候能够清楚的告诉 Master 从某个 binlog 的哪个位置开始往后的日志内容
5. Slave 的 SQL 进程检测到 relaylog 中新增加了内容后，会马上解析 relaylog 的内容成为在 Master 端真实执行时候的那些可执行的内容，并在自身执行。

#### 知识点
- binlog 不会记录不修改数据的语句，比如Select或者Show
- binlog 会重写日志中的密码，保证不以纯文本的形式出现
- MySQL 8 之后的版本可以选择对 binlog 进行加密
- 具体的写入时间：在事务提交的时候，数据库会把 binlog cache 写入 binlog 文件中，但并没有执行fsync()操作，即只将文件内容写入到 OS 缓存中。随后根据配置判断是否执行 fsync。
- 删除时间：保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

#### 内容：
- 逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
- 但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。
- 在使用mysqlbinlog解析binlog之后一些都会真相大白。
- 因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。

#### 什么时候产生：
- 事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
- 这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。
- 因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
- 这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。

#### 什么时候释放：
- binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

#### 对应的物理文件：
- 配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。
- 对于每个binlog日志文件，通过一个统一的index文件来组织。

#### 其他：
- 二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同
- 作用不同：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。
- 内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句
- 另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。
- 恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog
- 关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。


#### 管理
有这几个常用的命令可以查看 binlog 的状态：
- binlog 的配置信息：show variables like '%log_bin%';
- binlog 的格式：show variables like 'binlog_format';
- 日志的文件列表：show binary logs;
- 当前日志的写入状态：show master status;
- 清空 binlog 日志：reset master;

#### 格式
binlog 日志有 Row、Statement、Mixed 三种格式。可以通过 my.cnf 配置文件及 set global binlog_format='ROW/STATEMENT/MIXED'进行修改，命令行 show variables like 'binlog_format' 命令查看 binglog 格式。

#### Row格式
Row 格式仅保存记录被修改细节，不记录 sql 语句上下文相关信息。新版本的 MySQL 默认是 Row 格式。

- 优点：能非常清晰的记录下每行数据的修改细节，不需要记录上下文相关信息，因此不会发生某些特定情况下的存储过程、函数或者触发器的调用触发无法被正确复制的问题，任何情况都可以被复制，且能加快从库重放日志的效率，保证从库数据的一致性
- 缺点：由于所有的执行的语句在日志中都将以每行记录的修改细节来记录，因此，可能会产生大量的日志内容，干扰内容也较多。比如一条 update 语句，如修改多条记录，则 binlog 中每一条修改都会有记录，这样造成 binlog 日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中，实际等于重建了表。


#### Statement格式
每一条会修改数据的 sql 都会记录在 binlog 中。

- 优点：
   - 只需要记录执行语句的细节和上下文环境，避免了记录每一行的变化，在一些修改记录较多的情况下相比 Row 格式能大大减少 binlog 日志量，节约 IO，提高性能。
   - 另外还可以用于实时的还原。
   - 主从版本可以不一样，从服务器版本可以比主服务器版本高。
- 缺点：
   - 为了保证 sql 语句能在 slave 上正确执行，必须记录上下文信息，以保证所有语句能在 slave 得到和在 master 端执行时候相同的结果。
   - 另外，主从复制时，存在部分函数（如 sleep）及存储过程在 slave 上会出现与 master 结果不一致的情况，而相比 Row 记录每一行的变化细节，绝不会发生这种不一致的情况。

#### Mixed格式
以上两种格式混合。

经过前面的对比，可以发现 Row 和 Statement 各有优势，如果可以根据 sql 语句取舍可能会有更好地性能和效果。Mixed 便是以上两种形式的结合。不过，新版本的 MySQL 对 Row 模式也做了优化，并不是所有的修改都会完全以 Row 形式来记录，像遇到表结构变更的时候就会以 Statement 模式来记录，如果 SQL 语句确实就是 update 或者 delete 等修改数据的语句，那么还是会记录所有行的变更；因此，现在一般使用 Row 即可。


### 三种日志总结
首先 InnoDB 完成一次更新操作的具体步骤：
- 开启事务
- 查询待更新的记录到内存，并加 X 锁
- 记录 undo log 到内存 buffer
- 记录 redo log 到内存 buffer
- 更改内存中的数据记录
- 提交事务，触发 redo log 刷盘
- 记录 bin log
- 事务结束

既然有两种日志，就会有一个写入的策略问题，这个问题也就引出了另一个概念——两阶段提交。所谓两阶段提交，其实就是将redo的提交拆分成了prepare和commit两个阶段，注意这里的commit不是commit语句，是一种状态。

当事务发起commit的时候，根据上面的描述，首先会将脏数据块写入redo log，但是此时还没有写binlog，因此阶段处于prepare阶段，只有当binlog完成了写操作之后，才会将redo log标记为commit，这个事务才算是真的完结了。

这时，我们来思考一个问题，如果写binlog的时候crash了，怎么办？因为redo log还是处于prepare状态，实际上事务没有真的commit，因此是会回滚的。




### 错误日志
错误日志记录着mysqld启动和停止,以及服务器在运行过程中发生的错误的相关信息。在默认情况下，系统记录错误日志的功能是关闭的，错误信息被输出到标准错误输出。

指定日志路径两种方法:
- 编辑my.cnf 写入 log-error=[path]
- 通过命令参数错误日志 mysqld_safe –user=mysql –log-error=[path] &

显示错误日志的命令
```sql
show variables like 'err';
```

### 普通查询日志 general query log 
记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误，general log 都会将其记录下来 ，记录的格式为 {Time ，Id ，Command，Argument }。也正因为mysql服务器需要不断地记录日志，开启General log会产生不小的系统开销。 因此，Mysql默认是把General log关闭的。

查看日志的存放方式
```sql
show variables like 'log_output';

set global log_output='table'； 　-- 设置日志结果会记录到名为gengera_log的表中，这表的默认引擎都是CSV

set global log_output='file';    -- 设置表数据存储到文件
set global general_log_file=’/tmp/general.log’; -- 设置general log的日志文件路径

set global general_log=on;  -- 开启general log： 
set global general_log=off;  --　关闭general log： 
```

### 慢查询日志 
慢日志记录执行时间过长和没有使用索引的查询语句，报错select、update、delete以及insert语句，慢日志只会记录执行成功的语句。

```sql
--  查看慢查询时间
show variables like "long_query_time"; -- 默认10s

-- 查看慢查询配置情况： 
show status like "%slow_queries%";

-- 查看慢查询日志路径： 
show variables like "%slow%";

-- 开启慢日志
 set global slow_query_log=1;

-- 查看已经开启
show variables like "slow_query_log";
```

